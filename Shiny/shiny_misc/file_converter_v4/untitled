

read_data = function(input, type, quote){


  if(type == "/t"){
    df = read.delim(input, header=T, sep = "\t", row.names=NULL, quote=quote, stringsAsFactors=F)
  }
  if(type == "|"){
    df = read.delim(input, header=T, sep = "|", row.names=NULL, quote=quote, stringsAsFactors=F)
  }
  if(type == ","){

   df = read.csv(input, quote=quote, stringsAsFactors=F)
 }
 if(type == "excel"){

  #read.xls2 seems to work for all files, xls does not  
  #df = read.xls(input, sheet=1, method="csv", perl="perl")
  df = read.xlsx2(input,header=TRUE,sheetIndex=1)


    #df = names(df)
  }
    print("running read_data")

  #df = as.data.frame
 
   return(df)

 }
#remove X -----------------------------------------------------------------------------

remove_x = function(df){
  name = names(df)
  new_names = gsub("X_", "_", name)
  colnames(df) = new_names
  return(df)

}

#Split duplicates by col ----------------------------------------------------------------------
split_dupes_by_col = function(df, unique_identifier){
  dupe_array = df[unique_identifier]
  dupes = df[duplicated(dupe_array) == T,]
  non_dupes = df[duplicated(dupe_array) == F,]
  files = list(dupes, non_dupes)
  print(paste0("this is the unique identifier", unique_identifier))
  return(files)

}

#Split duplicates by all rows ----------------------------------------------------------------------
dedupe_by_all_rows = function(df){
  dupes = df[duplicated(df) == T,]
  unique = df[duplicated(df) == F,]
  files = list(dupes,unique)
  return(files)
  
}



#Dropdown return column selected ------------------------------------------------------------------------

return_columns = function(df){
  colname = names(df)
  array = character(0)

  for(i in 1:length(colname)){
    len = length(unique(df[i]))
    if(len == 1 && is.na(unique(df[i]))) {
      next
    }
    else {
      array = c(array, colname[i])
    }       
  }
  array
  return(array)
}

  #Return Unique Rows ---------------------------------------------------------------------------------

  return_unique = function(df){
    colname = names(df)
    array = character(0)

    for(i in 1:length(colname)){
      len = length(unique(df[i]))
      if(len == 1 && is.na(unique(df[i]))) {
        next
      }
      else  {
        array = c(array, colname[i])
      }       
    }
    return(array)
  }

  # Make Plot Function  ---------------------------------------------------------------------------------------------------------------------------------

make_plot = function(){
  df = grab_file()
  col = grab_col()

   df = df[order(df[,col]),]
   x_data = df[col]
   max_c = max(table(df[col]))

    if (max_c < 100){
  
  plot_test <- ggplot(df, aes_string(x_data))
  plot_test = plot_test + geom_histogram(aes_string(fill = (df[col]))) + 
        stat_bin(geom="text", aes(label = paste0((round((..count..)/sum(..count..)*100)),"%"), vjust=-1)) + expand_limits(y=c(0,max_c+1)) +
        xlab(col)+ scale_fill_brewer(palette="Spectral")+ theme(legend.position="none", axis.text.x=element_text(angle=-45,hjust=0))


    } else {
   plot_test <- ggplot(df, aes_string(x_data))
  plot_test = plot_test + geom_histogram(aes_string(fill = (df[col]))) + 
        stat_bin(geom="text", aes(label =paste0((round((..count..)/sum(..count..)*100)),"%"), vjust=-1)) + expand_limits(y=c(0,max_c+10)) +
        xlab(col)+ scale_fill_brewer(palette="Set1")+ theme(legend.position="none", axis.text.x=element_text(angle=-45,hjust=0))

    } 
    return(plot_test)
}
# URL Validator -------------------------------------------------------------------------------------------


url_validator = function(df, col){
  col_name = col
  col1 = df[col_name]
  col2 = gsub("http://", "", as.matrix(col1))
  col2 = paste0("http://", col2)
  df[col_name] = col2

  df$error_code = ""
  df$url_exist = ""

  for(i in 1:nrow(df)){
    array = df[col]  
    url = array[i,]
    cmd = paste0("curl -s --head ", url, "/ --max-time 5 | head -n 1")
    output = system(cmd, intern=T)
    if(length(output) > 0){
      df$error_code[i] = output
      if(grepl("404", output)){
        df$url_exist[i] = "false"
      } else {
        df$url_exist[i] = "true" 
      }
    } else {
      df$url_exist[i] = "no response"
      print(" no response just went off fool")
    }
    
  }
  url_array = df["url_exist"]
  broke = df[url_array == "no response",]
  broke2 = df[url_array == "false",]
  broke = rbind(broke, broke2)
  not_broke = df[url_array == "true",]
  files= list(broke, not_broke)
  return(files)
}



# # Ensures all urls have http in front
# http_adder = function(df,col_name ){
# col_name = as.character(col_name)
# col = df[col_name]
# col2 = gsub("http://", "", as.matrix(col))
# col2 = paste0("http://", col2)
# print("in http adder")
# df[col_name] = col2
# return(df)

# }

#column summary ---------------------------------------------------------------------------------------

dupe_summary = function(output, unique_identifier){

  rows = nrow(output)
  unique_array = output[unique_identifier]
  dupes = unique_array[duplicated(unique_array) == T,]
  dupe_length = length(dupes)



  #Dupes
  summary = paste(paste0("<hr><h3><span style='color:red'>Duplicates</span> = <strong>", dupe_length, "</strong></h3>"),paste0("<p>Total Rows =","<strong>",rows, "</strong></p>"), sep = "\n")
  return(summary)
}



#Output Summary ---------------------------------------------------------------------------------------
output_summary = function(output){

  rows = nrow(output)
  #unique_array = output[unique_identifier]
  #dupes = unique_array[duplicated(unique_array) == T,]
  #dupe_length = length(dupes)
  summary = ""


  #Dupes
  #summary = paste(paste0("<hr><h3><span style='color:red'>Duplicates</span> = <strong>", dupe_length, "</strong></h3>"),paste0("<p>Total Rows =","<strong>",rows, "</strong></p>"), sep = "\n")
  
#Answer distros
  summary = c(summary," <hr> ",  "<h4 style='color:green'>Answer Distributions</h4><h6 style='color:grey'>Lists the count of each unique value for every column. Columns with more than 12 unique values will not display</h6>")
  names = names(output)

  for(i in 1:length(names)){
    array = output[i]
    name = names(array)
    uni = unique(array)
    len = nrow(uni)
    #print(len)
    if(len > 1 & len < 12){
      summary = c(summary, "<strong>",names[i], "</strong><br>")
      for(j in 1:nrow(uni)){
         uni_variable = uni[j,]
          # print(uni_variable)
        occurance = length(array[array == uni_variable])
          if(j == 1){
 
        sum = paste0("<ul><li>",uni_variable, " = ", occurance, " / ", nrow(array),"</li>")
        } else if (j == nrow(uni)){
          sum = paste0("<li>",uni_variable, " = ", occurance, " / ", nrow(array),"</li></ul>")
        }
        else {
          sum = paste0("<li>",uni_variable, " = ", occurance, " / ", nrow(array),"</li>")
        }

        #print("did you make it here?")
        summary = c(summary, sum) 
      }
      
    }
  }
  
  #Blanks
  summary = c(summary, " <hr><h4 style='color:blue'>Empty Cells</h4><h6 style='color:grey'>Lists the number of empty cells for each column. Columns without any empty cells will not display.</h6>")
  names = names(output)
  
  for(i in 1:length(names)){
    col_array = output[i]
    blanks = col_array[col_array == "" ]
    if(length(blanks) > 1){

      len = length(blanks)
      name = names(col_array)
      col_sum = paste0("<p>",name, "  = <strong>", len, "/", rows, "</strong><p>")
      summary = c(summary, col_sum)
    }

    
  }

  return(summary) 
}    



# Table Limiter
# worker_table= profile_similar_workers()
# if (length(worker_table$X_worker_id) > 50){
# max_count = min(50, nrow(worker_table))
# worker_table = worker_table[1:max_count,]
# }



